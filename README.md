#  ML API with CI/CD (FastAPI + GitHub Actions + Docker + Render)

A simple **Machine Learning Operations (MLOps)** starter project that shows how to:

- Train a basic ML model (Iris classification)
- Serve predictions through a **FastAPI** web API
- Containerize the app using **Docker**
- Automate testing and deployment with **GitHub Actions**
- Deploy a live API on **Render**

This project is ideal for learning **CI/CD for machine learning** from end-to-end.

---

## ğŸ“‚ Project Structure

ml_api_cicd/
â”‚â”€â”€ train.py # Train and save the model
â”‚â”€â”€ predict.py # Model prediction logic
â”‚â”€â”€ main.py # FastAPI app
â”‚â”€â”€ requirements.txt # Python dependencies
â”‚â”€â”€ Dockerfile # Container definition
â”‚â”€â”€ tests/
â”‚ â””â”€â”€ test_api.py # Pytest-based API tests
â”‚â”€â”€ .github/
â”‚ â””â”€â”€ workflows/
â”‚ â”œâ”€â”€ ci.yml # CI pipeline: run tests/lint
â”‚ â””â”€â”€ cd.yml # CD pipeline: build & push Docker image
â””â”€â”€ README.md



---

## ğŸƒâ€â™‚ï¸ Quick Start (Local)

### 1ï¸âƒ£ Train the Model
```bash
python train.py

**RUN THE API**

uvicorn main:app --reload


Visit http://127.0.0.1:8000/docs
 for interactive Swagger UI.

Make a Prediction

Example curl request:

curl -X POST "http://127.0.0.1:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{"features": [5.1, 3.5, 1.4, 0.2]}'


Run with Docker

Build and run the container:

docker build -t ml-api .
docker run -p 8000:8000 ml-api


Open http://127.0.0.1:8000/docs
.

**CI/CD Workflow**

Continuous Integration (CI) â€“ .github/workflows/ci.yml

Runs automatically on every push or pull request

Installs dependencies

Runs pytest tests and linter checks

Continuous Deployment (CD) â€“ .github/workflows/cd.yml

Builds the Docker image

Pushes it to Docker Hub / GitHub Container Registry

Render automatically pulls the latest image and redeploys the live API


**Live API**

Base URL: https://<your-render-app-name>.onrender.com

Interactive docs:

https://<your-render-app-name>.onrender.com/docs

**Tech Stack**

Python 3.9

FastAPI â€“ REST API framework

scikit-learn â€“ ML model training

Docker â€“ Containerization

GitHub Actions â€“ CI/CD pipelines

Render â€“ Hosting and deployment

**Contributing**

Feel free to fork this repo, open issues, or submit pull requests if youâ€™d like to improve it.

**License**

This project is released under the MIT License.


---

ğŸ”§ **Tip:**  
Replace every `https://<your-render-app-name>.onrender.com` with your actual Render URL so people can try your live endpoint.


**Examples showing how a website (JavaScript/React) and a mobile app (Flutter/Dart) can call your live FastAPI endpoint**

**React Component example**

import React, { useState } from "react";
import axios from "axios";

export default function IrisPredictor() {
  const [features, setFeatures] = useState([5.1, 3.5, 1.4, 0.2]);
  const [prediction, setPrediction] = useState(null);

  const callAPI = async () => {
    try {
      const res = await axios.post(
        "https://<your-render-app-name>.onrender.com/predict",
        { features }
      );
      setPrediction(res.data.prediction);
    } catch (err) {
      console.error(err);
    }
  };

  return (
    <div>
      <h2>Iris Prediction</h2>
      <button onClick={callAPI}>Predict</button>
      {prediction !== null && <p>Prediction: {prediction}</p>}
    </div>
  );
}



